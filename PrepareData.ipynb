{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import copy\n",
    "import mmcv\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "import skimage.io as io\n",
    "from pycocotools.coco import COCO   # 载入 cocoz\n",
    "%matplotlib inline\n",
    "import random\n",
    "from PIL import Image\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_info(fp):\n",
    "    masks = []\n",
    "    labels = []\n",
    "    boxes = []\n",
    "    for line in fp:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        items = line.split(' ')\n",
    "        loc = [float(x) for x in items[:8]]\n",
    "        xs = loc[0::2]\n",
    "        ys = loc[1::2]\n",
    "        poly = np.array([[[loc[0],loc[1]],[loc[2],loc[3]],[loc[4],loc[5]],[loc[6], loc[7]]]], np.int32)\n",
    "        area = cv2.contourArea(poly)\n",
    "        xmin  = min(xs)\n",
    "        xmax = max(xs)\n",
    "        ymin = min(ys)\n",
    "        ymax = max(ys)\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        cls = items[8]\n",
    "        if cls not in CLASS:\n",
    "            continue\n",
    "        labels.append(cls)\n",
    "        masks.append(loc)\n",
    "        boxes.append([xmin,ymin,xmax,ymax])\n",
    "    return labels, masks, boxes\n",
    "\n",
    "def gen_ann(box, mask, label, annotations, obj_id, ID, xmin, ymin):\n",
    "    for b, loc, l in zip(box, mask, label):\n",
    "        x1, y1, x2, y2 = b\n",
    "        x1 -= xmin\n",
    "        y1 -= ymin\n",
    "        x2 -= xmin\n",
    "        y2 -= ymin\n",
    "        poly = np.array([[[loc[0],loc[1]],[loc[2],loc[3]],[loc[4],loc[5]],[loc[6], loc[7]]]], np.int32)\n",
    "        box = [x1, y1, x2, y2]\n",
    "        area = cv2.contourArea(poly)\n",
    "        poly = [loc[0]-xmin,loc[1]-ymin,loc[2]-xmin,loc[3]-ymin,loc[4]-xmin,loc[5]-ymin,loc[6]-xmin, loc[7]-ymin]\n",
    "        annotation = {\"id\" : obj_id, \n",
    "                \"image_id\" : ID, \n",
    "                \"category_id\" : class_to_ind[l], \n",
    "                \"segmentation\" : [poly], \n",
    "               \"area\" :  area, \n",
    "               \"bbox\" : [x1, y1, x2-x1, y2-y1], \n",
    "               \"iscrowd\" : 0,\n",
    "            }\n",
    "        obj_id += 1\n",
    "        annotations[\"annotations\"].append(annotation)\n",
    "    ID += 1\n",
    "    return annotations, obj_id, ID\n",
    "  #         poly = np.array([[[loc[0],loc[1]],[loc[2],loc[3]],[loc[4],loc[5]],[loc[6], loc[7]]]], np.int32)\n",
    "            #         img2 = cv2.polylines(img2, poly, 1,(0,255,0), 1)\n",
    "                    #cv2.rectangle(img2 , (int(x1), int(y1)), (int(x2), int(y2)), (0,255,0), 2)\n",
    "            #         poly = np.array([[[loc[0]-xmin,loc[1]-ymin],[loc[2]-xmin,loc[3]-ymin],[loc[4]-xmin,loc[5]-ymin],[loc[6]-xmin, loc[7]-ymin]]], np.int32)\n",
    "            #         cv2.polylines(img2, poly, 1,(0,255,0), 2)\n",
    "            #         cv2.fillPoly(img2, poly, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bbox_overlaps_py(boxes, query_boxes):\n",
    "    \"\"\"\n",
    "    determine overlaps between boxes and query_boxes\n",
    "    :param boxes: n * 4 bounding boxes\n",
    "    :param query_boxes: k * 4 bounding boxes\n",
    "    :return: overlaps: n * k overlaps\n",
    "    \"\"\"\n",
    "    n_ = boxes.shape[0]\n",
    "    k_ = query_boxes.shape[0]\n",
    "    overlaps = np.zeros((n_, k_), dtype=np.float)\n",
    "    for k in range(k_):\n",
    "        query_box_area = (query_boxes[k, 2] - query_boxes[k, 0] + 1) * (query_boxes[k, 3] - query_boxes[k, 1] + 1)\n",
    "        for n in range(n_):\n",
    "            iw = min(boxes[n, 2], query_boxes[k, 2]) - max(boxes[n, 0], query_boxes[k, 0]) + 1\n",
    "            if iw > 0:\n",
    "                ih = min(boxes[n, 3], query_boxes[k, 3]) - max(boxes[n, 1], query_boxes[k, 1]) + 1\n",
    "                if ih > 0:\n",
    "                    box_area = (boxes[n, 2] - boxes[n, 0] + 1) * (boxes[n, 3] - boxes[n, 1] + 1)\n",
    "                    all_area = float(query_box_area)\n",
    "                    overlaps[n, k] = iw * ih / all_area\n",
    "    return overlaps\n",
    "\n",
    "def _pygenerate(boxes, masks, labels, width, height, chipsize, stride):\n",
    "        chips = []\n",
    "        boxes = np.array(boxes)\n",
    "        masks = np.array(masks)\n",
    "        # ensure coverage of image for worst case\n",
    "        # corners\n",
    "        chips.append([max(width - chipsize, 0), 0, width - 1, min(chipsize, height-1)])\n",
    "        chips.append([0, max(height - chipsize, 0), min(chipsize, width-1), height-1])\n",
    "        chips.append([max(width - chipsize, 0), max(height - chipsize, 0), width-1, height-1])\n",
    "\t\t\n",
    "        for i in range(0, width - int(chipsize), stride):\n",
    "            for j in range(0, height - int(chipsize), stride):\n",
    "                x1 = i\n",
    "                y1 = j\n",
    "                x2 = i + chipsize - 1\n",
    "                y2 = j + chipsize - 1\n",
    "                chips.append([x1, y1, x2, y2])\n",
    "\t\t#width may not be divide by stride\n",
    "        for j in range(0, height - int(chipsize), stride):\n",
    "            x1 = max(width - chipsize - 1,0)\n",
    "            y1 = j\n",
    "            x2 = width - 1\n",
    "            y2 = j + chipsize - 1\n",
    "            chips.append([x1, y1, x2, y2])\n",
    "\t\t#the same as above\n",
    "        for i in range(0, width - int(chipsize), stride):\n",
    "            x1 = i\n",
    "            y1 = max(height - chipsize - 1,0)\n",
    "            x2 = i + chipsize - 1\n",
    "            y2 = height - 1\n",
    "            chips.append([x1, y1, x2, y2])\n",
    "\n",
    "        chips = np.array(chips).astype(np.float)\n",
    "        overlaps = bbox_overlaps_py(chips, boxes.astype(np.float))\n",
    "        fchips = []\n",
    "        masks_list = []\n",
    "        boxes_list = []\n",
    "        labels_list = []\n",
    "        for j in range(len(chips)):\n",
    "            nvids = np.where(overlaps[j, :] >= 0.9)[0]\n",
    "            if(len(nvids) == 0):\n",
    "                continue\n",
    "            else:\n",
    "                fchips.append(chips[j])\n",
    "                boxes_list.append(boxes[nvids])\n",
    "                masks_list.append(masks[nvids])\n",
    "                labels_list.append([labels[x] for x in nvids])\n",
    "        return fchips, masks_list, boxes_list, labels_list\n",
    "\n",
    "def test_pygenerate(width, height, chipsize, stride):\n",
    "        chips = []\n",
    "        # ensure coverage of image for worst case\n",
    "        # corners\n",
    "        chips.append([max(width - chipsize, 0), 0, width - 1, min(chipsize, height-1)])\n",
    "        chips.append([0, max(height - chipsize, 0), min(chipsize, width-1), height-1])\n",
    "        chips.append([max(width - chipsize, 0), max(height - chipsize, 0), width-1, height-1])\n",
    "\t\t\n",
    "        for i in range(0, width - int(chipsize), stride):\n",
    "            for j in range(0, height - int(chipsize), stride):\n",
    "                x1 = i\n",
    "                y1 = j\n",
    "                x2 = i + chipsize - 1\n",
    "                y2 = j + chipsize - 1\n",
    "                chips.append([x1, y1, x2, y2])\n",
    "\t\t#width may not be divide by stride\n",
    "        for j in range(0, height - int(chipsize), stride):\n",
    "            x1 = max(width - chipsize - 1,0)\n",
    "            y1 = j\n",
    "            x2 = width - 1\n",
    "            y2 = j + chipsize - 1\n",
    "            chips.append([x1, y1, x2, y2])\n",
    "\t\t#the same as above\n",
    "        for i in range(0, width - int(chipsize), stride):\n",
    "            x1 = i\n",
    "            y1 = max(height - chipsize - 1,0)\n",
    "            x2 = i + chipsize - 1\n",
    "            y2 = height - 1\n",
    "            chips.append([x1, y1, x2, y2])\n",
    "\n",
    "        chips = np.array(chips).astype(np.float)\n",
    "        return chips\n",
    "def generate_test(datdir, phase):\n",
    "    info = {\n",
    "        \"description\": \"rscup\",\n",
    "        \"url\": \"http://cocodataset.org\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2014,\n",
    "        \"contributor\": \"COCO Consortium\",\n",
    "        \"date_created\": \"2017/09/01\"\n",
    "      }\n",
    "    license = [{ \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\", \"id\": 1, \"name\": \"Attribution-NonCommercial-ShareAlike License\"} ]\n",
    "    categories = []\n",
    "    for cls in CLASS:\n",
    "        category = { \"id\" : class_to_ind[cls], \"name\" : cls, \"supercategory\" : \"object\",}\n",
    "        categories.append(category)\n",
    "\n",
    "    annotations = {\"info\": info, \"images\": [], \"annotations\": [], \"categories\":categories, \"license\":license}\n",
    "    imgs = os.listdir(datadir)\n",
    "    ID = 0\n",
    "    for img_id in tqdm(range(len(imgs))):\n",
    "        img_path = os.path.join(datadir, imgs[img_id])\n",
    "        img = cv2.imread(img_path)\n",
    "        H,W,_ = img.shape\n",
    "        if max(H,W) > 512:\n",
    "            fchips = test_pygenerate(W, H, 512, 416)\n",
    "            count = 0\n",
    "            for chip in fchips:\n",
    "                count+=1\n",
    "                xmin, ymin, xmax, ymax = chip\n",
    "                filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_\".format(str(xmin), str(ymin))+\"_part\" +str(count) + \".jpg\"\n",
    "                image = { \"license\": 1,\n",
    "                          \"file_name\": filename,\n",
    "                          \"coco_url\": \"xxx\",\n",
    "                          \"height\": ymax-ymin,\n",
    "                          \"width\": xmax-xmin,\n",
    "                          \"date_captured\": \"2019-06-25\",\n",
    "                          \"flickr_url\": \"xxx\",\n",
    "                          \"id\": ID\n",
    "                        }\n",
    "                ID += 1\n",
    "                annotations[\"images\"].append(image)\n",
    "                img2 = copy.deepcopy(img[int(ymin):int(ymax), int(xmin):int(xmax),:])\n",
    "                cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img2)\n",
    "        else:\n",
    "            filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_\".format(str(0), str(0))+\"_part\" +str(0) + \".jpg\"\n",
    "            image = { \"license\": 1,\n",
    "                          \"file_name\": filename,\n",
    "                          \"coco_url\": \"xxx\",\n",
    "                          \"height\": H,\n",
    "                          \"width\": W,\n",
    "                          \"date_captured\": \"2019-06-25\",\n",
    "                          \"flickr_url\": \"xxx\",\n",
    "                          \"id\": ID\n",
    "                        }\n",
    "            ID += 1\n",
    "            annotations[\"images\"].append(image)\n",
    "            cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img)\n",
    "    with open('./rscup/annotation/annos_rscup_'+phase+'.json', 'w') as json_file:\n",
    "        json.dump(annotations, json_file, cls=MyEncoder)\n",
    "        \n",
    "def generate_anno(filename, height, width, ID):\n",
    "    image = { \"license\": 1,\n",
    "              \"file_name\": filename,\n",
    "              \"coco_url\": \"xxx\",\n",
    "              \"height\": height,\n",
    "              \"width\": width,\n",
    "              \"date_captured\": \"2019-06-25\",\n",
    "              \"flickr_url\": \"xxx\",\n",
    "              \"id\": ID\n",
    "            }\n",
    "    return image\n",
    "        \n",
    "def scale_generate_test(datdir, phase, SCALE):\n",
    "    imgs = os.listdir(datadir)\n",
    "    rotate90 = iaa.Sequential(\n",
    "    [iaa.Affine(rotate=90)])\n",
    "    rotate090 = iaa.Sequential(\n",
    "    [iaa.Affine(rotate=-90)])\n",
    "    info = {\n",
    "        \"description\": \"rscup\",\n",
    "        \"url\": \"http://cocodataset.org\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2014,\n",
    "        \"contributor\": \"COCO Consortium\",\n",
    "        \"date_created\": \"2017/09/01\"\n",
    "      }\n",
    "    license = [{ \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\", \"id\": 1, \"name\": \"Attribution-NonCommercial-ShareAlike License\"} ]\n",
    "    categories = []\n",
    "    for cls in CLASS:\n",
    "        category = { \"id\" : class_to_ind[cls], \"name\" : cls, \"supercategory\" : \"object\",}\n",
    "        categories.append(category)\n",
    "    print(categories)\n",
    "    annotations = {\"info\": info, \"images\": [], \"annotations\": [], \"categories\":categories, \"license\":license}\n",
    "    obj_id = 0\n",
    "    ID = 0\n",
    "    for img_id in tqdm(range(len(imgs))):\n",
    "        img_path = os.path.join(datadir, imgs[img_id])\n",
    "        original_img = cv2.imread(img_path)\n",
    "        h, w, _ = original_img.shape\n",
    "        scales = copy.deepcopy(SCALE)\n",
    "#         if(max(h, w) > 10000):\n",
    "#             scales.append(0.1)\n",
    "        for scale in scales:\n",
    "            img, scale_factor = mmcv.imrescale(original_img, scale, return_scale=True)\n",
    "            H,W,_ = img.shape\n",
    "            if max(H,W) > 512:\n",
    "                fchips = test_pygenerate(W, H, 512, 416)\n",
    "                count = 0\n",
    "                for chip in  fchips:\n",
    "                    count+=1\n",
    "                    xmin, ymin, xmax, ymax = chip\n",
    "                    img2 = copy.deepcopy(img[int(ymin):int(ymax), int(xmin):int(xmax),:])\n",
    "                    hh, ww, _ = img2.shape\n",
    "                    filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(xmin), str(ymin), str(0))+\"part\" +str(count) + \".jpg\"\n",
    "                    cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img2)\n",
    "                    image = generate_anno(filename, hh, ww, ID)\n",
    "                    annotations[\"images\"].append(image)\n",
    "                    ID += 1\n",
    "                    \n",
    "#                     filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(xmin), str(ymin), str(90))+\"part\" +str(count) + \".jpg\"\n",
    "#                     img_rotate90 = rotate90.augment_image(img2)\n",
    "#                     cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img_rotate90)\n",
    "#                     image = generate_anno(filename, hh, ww, ID)\n",
    "#                     annotations[\"images\"].append(image)\n",
    "#                     ID += 1\n",
    "                    \n",
    "#                     filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(xmin), str(ymin), str(-90))+\"part\" +str(count) + \".jpg\"\n",
    "#                     img_rotate090 = rotate090.augment_image(img2)\n",
    "#                     cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img_rotate090)\n",
    "#                     image = generate_anno(filename, hh, ww, ID)\n",
    "#                     annotations[\"images\"].append(image)\n",
    "#                     ID += 1     \n",
    "            else:\n",
    "                filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(0), str(0), str(0))+\"part\" +str(0) + \".jpg\"\n",
    "                image = generate_anno(filename, H, W, ID)\n",
    "                annotations[\"images\"].append(image)\n",
    "                ID += 1\n",
    "                cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img)\n",
    "                \n",
    "#                 img_rotate90 = rotate90.augment_image(img)\n",
    "#                 filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(0), str(0), str(90))+\"part\" +str(0) + \".jpg\"\n",
    "#                 image = generate_anno(filename, H, W, ID)\n",
    "#                 annotations[\"images\"].append(image)\n",
    "#                 ID += 1\n",
    "#                 cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img_rotate90)\n",
    "                \n",
    "#                 img_rotate090 = rotate090.augment_image(img)\n",
    "#                 filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(0), str(0), str(-90))+\"part\" +str(0) + \".jpg\"\n",
    "#                 image = generate_anno(filename,H,W, ID)\n",
    "#                 annotations[\"images\"].append(image)\n",
    "#                 ID += 1\n",
    "#                 cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img_rotate090)\n",
    "                \n",
    "    with open('./rscup/annotation/annos_rscup_'+phase+'.json', 'w') as json_file:\n",
    "        json.dump(annotations, json_file, cls=MyEncoder)\n",
    "    print(\"totol number {}\".format(str(ID)))\n",
    "\n",
    "    \n",
    "def increment_generate(datdir, phase):\n",
    "    imgs = os.listdir(datadir)\n",
    "    coco=COCO('./rscup/annotation/annos_rscup_'+phase+'.json')\n",
    "    annotations = mmcv.load('./rscup/annotation/annos_rscup_'+phase+'.json')\n",
    "    imgids = coco.getImgIds()\n",
    "    ID = max(imgids)+1\n",
    "    for img_id in tqdm(range(len(imgs))):\n",
    "        img_path = os.path.join(datadir, imgs[img_id])\n",
    "        original_img = cv2.imread(img_path)\n",
    "        h, w, _ = original_img.shape\n",
    "        scale_factor = 512 /  max(h, w)\n",
    "        img, scale_factor = mmcv.imrescale(original_img, scale_factor, return_scale=True)\n",
    "        H,W,_ = img.shape\n",
    "        filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale_factor), str(0), str(0), str(0))+\"part\" +str(0) + \".jpg\"\n",
    "        image = { \"license\": 1,\n",
    "                          \"file_name\": filename,\n",
    "                          \"coco_url\": \"xxx\",\n",
    "                          \"height\": H,\n",
    "                          \"width\": W,\n",
    "                          \"date_captured\": \"2019-06-25\",\n",
    "                          \"flickr_url\": \"xxx\",\n",
    "                          \"id\": ID\n",
    "                        }\n",
    "        ID += 1\n",
    "        cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img)\n",
    "        annotations[\"images\"].append(image)\n",
    "        \n",
    "    with open('./rscup/annotation/annos_rscup_'+phase+'.json', 'w') as json_file:\n",
    "        json.dump(annotations, json_file, cls=MyEncoder)\n",
    "    print(\"totol number {}\".format(str(ID)))    \n",
    "    \n",
    "    \n",
    "\n",
    "def generate_nopatch(datdir, labeldir, phase):\n",
    "    imgs = os.listdir(datadir)\n",
    "    info = {\n",
    "        \"description\": \"rscup\",\n",
    "        \"url\": \"http://cocodataset.org\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2014,\n",
    "        \"contributor\": \"COCO Consortium\",\n",
    "        \"date_created\": \"2017/09/01\"\n",
    "      }\n",
    "    license = [{ \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\", \"id\": 1, \"name\": \"Attribution-NonCommercial-ShareAlike License\"} ]\n",
    "    categories = []\n",
    "    for cls in CLASS:\n",
    "        category = { \"id\" : class_to_ind[cls], \"name\" : cls, \"supercategory\" : \"object\",}\n",
    "        categories.append(category)\n",
    "\n",
    "    annotations = {\"info\": info, \"images\": [], \"annotations\": [], \"categories\":categories, \"license\":license}\n",
    "    obj_id = 0\n",
    "    ID = 0\n",
    "    for img_id in tqdm(range(len(imgs))):\n",
    "        img_path = os.path.join(datadir, imgs[img_id])\n",
    "        img = cv2.imread(img_path)\n",
    "        H,W,_ = img.shape\n",
    "        label_path = os.path.join(labeldir, imgs[img_id].split(\".\")[0]+\".txt\")\n",
    "        fp = open(label_path).readlines()[2:]\n",
    "        labels, masks, boxes = get_info(fp)\n",
    "       \n",
    "        filename = imgs[img_id]\n",
    "        image = { \"license\": 1,\n",
    "                      \"file_name\": filename,\n",
    "                      \"coco_url\": \"xxx\",\n",
    "                      \"height\": H,\n",
    "                      \"width\": W,\n",
    "                      \"date_captured\": \"2019-06-25\",\n",
    "                      \"flickr_url\": \"xxx\",\n",
    "                      \"id\": ID\n",
    "                    }\n",
    "\n",
    "        #cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img)\n",
    "        annotations[\"images\"].append(image)\n",
    "        annotations, obj_id, ID = gen_ann(boxes, masks, labels, annotations, obj_id, ID,0, 0)\n",
    "    with open('./data/annotation/annos_rscup_'+phase+'.json', 'w') as json_file:\n",
    "        json.dump(annotations, json_file, cls=MyEncoder)\n",
    "\n",
    "        \n",
    "def get_scale_info(fp, scale):\n",
    "    masks = []\n",
    "    labels = []\n",
    "    boxes = []\n",
    "    for line in fp:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        items = line.split(' ')\n",
    "        loc = np.array([float(x) for x in items[:8]])\n",
    "        loc = loc*scale\n",
    "        xs = loc[0::2]\n",
    "        ys = loc[1::2]\n",
    "        poly = np.array([[[loc[0],loc[1]],[loc[2],loc[3]],[loc[4],loc[5]],[loc[6], loc[7]]]], np.int32)\n",
    "        area = cv2.contourArea(poly)\n",
    "        if(area < 50):\n",
    "            continue\n",
    "        xmin  = min(xs)\n",
    "        xmax = max(xs)\n",
    "        ymin = min(ys)\n",
    "        ymax = max(ys)\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        cls = items[8]\n",
    "        if cls not in CLASS:\n",
    "            continue\n",
    "        labels.append(cls)\n",
    "        masks.append(loc)\n",
    "        boxes.append([xmin,ymin,xmax,ymax])\n",
    "    return labels, masks, boxes\n",
    "        \n",
    "def scale_generate(datdir, labeldir, phase, SCALE):\n",
    "    imgs = os.listdir(datadir)\n",
    "    info = {\n",
    "        \"description\": \"rscup\",\n",
    "        \"url\": \"http://cocodataset.org\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2014,\n",
    "        \"contributor\": \"COCO Consortium\",\n",
    "        \"date_created\": \"2017/09/01\"\n",
    "      }\n",
    "    license = [{ \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\", \"id\": 1, \"name\": \"Attribution-NonCommercial-ShareAlike License\"} ]\n",
    "    categories = []\n",
    "    for cls in CLASS:\n",
    "        category = { \"id\" : class_to_ind[cls], \"name\" : cls, \"supercategory\" : \"object\",}\n",
    "        categories.append(category)\n",
    "    print(categories)\n",
    "    annotations = {\"info\": info, \"images\": [], \"annotations\": [], \"categories\":categories, \"license\":license}\n",
    "    obj_id = 0\n",
    "    ID = 0\n",
    "    for img_id in tqdm(range(len(imgs))):\n",
    "        img_path = os.path.join(datadir, imgs[img_id])\n",
    "        label_path = os.path.join(labeldir, imgs[img_id].split(\".\")[0]+\".txt\")\n",
    "        original_img = cv2.imread(img_path)\n",
    "        h, w, _ = original_img.shape\n",
    "        scales = copy.deepcopy(SCALE)\n",
    "#         if(max(h, w) > 10000):\n",
    "#             scales.append(0.1)\n",
    "        fp = open(label_path).readlines()[2:]\n",
    "        for scale in scales:\n",
    "            img, scale_factor = mmcv.imrescale(original_img, scale, return_scale=True)\n",
    "            H,W,_ = img.shape\n",
    "            labels, masks, boxes = get_scale_info(fp, scale_factor)\n",
    "            if(len(labels)<=0):\n",
    "                continue\n",
    "            if max(H,W) > 512:\n",
    "                fchips, masks, boxes, labels = _pygenerate(boxes, masks, labels, W, H, 512, 416)\n",
    "                count = 0\n",
    "                for chip, mask, box, label in zip(fchips, masks, boxes,labels):\n",
    "                    count+=1\n",
    "                    xmin, ymin, xmax, ymax = chip\n",
    "                    filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(xmin), str(ymin), str(0))+\"part\" +str(count) + \".jpg\"\n",
    "                    img2 = copy.deepcopy(img[int(ymin):int(ymax), int(xmin):int(xmax),:])\n",
    "                    cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img2)\n",
    "                    image = { \"license\": 1,\n",
    "                              \"file_name\": filename,\n",
    "                              \"coco_url\": \"xxx\",\n",
    "                              \"height\": ymax-ymin,\n",
    "                              \"width\": xmax-xmin,\n",
    "                              \"date_captured\": \"2019-06-25\",\n",
    "                              \"flickr_url\": \"xxx\",\n",
    "                              \"id\": ID\n",
    "                            }\n",
    "                    annotations[\"images\"].append(image)\n",
    "                    annotations, obj_id, ID = gen_ann(box, mask, label, annotations, obj_id, ID, xmin, ymin)\n",
    "            else:\n",
    "                filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(0), str(0), str(0))+\"part\" +str(0) + \".jpg\"\n",
    "                image = { \"license\": 1,\n",
    "                              \"file_name\": filename,\n",
    "                              \"coco_url\": \"xxx\",\n",
    "                              \"height\": H,\n",
    "                              \"width\": W,\n",
    "                              \"date_captured\": \"2019-06-25\",\n",
    "                              \"flickr_url\": \"xxx\",\n",
    "                              \"id\": ID\n",
    "                            }\n",
    "\n",
    "                cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img)\n",
    "                annotations[\"images\"].append(image)\n",
    "                annotations, obj_id, ID = gen_ann(boxes, masks, labels, annotations, obj_id, ID,0, 0)\n",
    "    with open('./rscup/annotation/annos_rscup_'+phase+'.json', 'w') as json_file:\n",
    "        json.dump(annotations, json_file, cls=MyEncoder)\n",
    "    print(\"totol number {}\".format(str(ID)))\n",
    "    \n",
    "    \n",
    "def increment_train_generate(datdir, labeldir, phase):\n",
    "    imgs = os.listdir(datadir)\n",
    "    imgs = os.listdir(datadir)\n",
    "    coco=COCO('./rscup/annotation/annos_rscup_'+phase+'.json')\n",
    "    annotations = mmcv.load('./rscup/annotation/annos_rscup_'+phase+'.json')\n",
    "    imgids = coco.getImgIds()\n",
    "    annids = coco.getAnnIds()\n",
    "    ID = max(imgids)+1\n",
    "    obj_id = max(annids)+1\n",
    "    for img_id in tqdm(range(len(imgs))):\n",
    "        img_path = os.path.join(datadir, imgs[img_id])\n",
    "        label_path = os.path.join(labeldir, imgs[img_id].split(\".\")[0]+\".txt\")\n",
    "        original_img = cv2.imread(img_path)\n",
    "        h, w, _ = original_img.shape\n",
    "        scale = 512 /  max(h, w)\n",
    "#         if(max(h, w) > 10000):\n",
    "#             scales.append(0.1)\n",
    "        fp = open(label_path).readlines()[2:]\n",
    "        img, scale_factor = mmcv.imrescale(original_img, scale, return_scale=True)\n",
    "        H,W,_ = img.shape\n",
    "        labels, masks, boxes = get_scale_info(fp, scale_factor)\n",
    "        if(len(labels)<=0):\n",
    "            continue\n",
    "        filename = imgs[img_id].split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(0), str(0), str(0))+\"part\" +str(0) + \".jpg\"\n",
    "        image = { \"license\": 1,\n",
    "                      \"file_name\": filename,\n",
    "                      \"coco_url\": \"xxx\",\n",
    "                      \"height\": H,\n",
    "                      \"width\": W,\n",
    "                      \"date_captured\": \"2019-06-25\",\n",
    "                      \"flickr_url\": \"xxx\",\n",
    "                      \"id\": ID\n",
    "                    }\n",
    "\n",
    "        cv2.imwrite(\"./rscup/{}/\".format(phase)+filename, img)\n",
    "        annotations[\"images\"].append(image)\n",
    "        annotations, obj_id, ID = gen_ann(boxes, masks, labels, annotations, obj_id, ID,0, 0)\n",
    "    with open('./rscup/annotation/annos_rscup_'+phase+'.json', 'w') as json_file:\n",
    "        json.dump(annotations, json_file, cls=MyEncoder)\n",
    "    print(\"totol number {}\".format(str(ID)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASS=['tennis-court', 'container-crane', 'storage-tank', 'baseball-diamond', 'plane', 'ground-track-field', 'helicopter', 'airport', 'harbor', 'ship', 'large-vehicle', 'swimming-pool', 'soccer-ball-field', 'roundabout', 'basketball-court', 'bridge', 'small-vehicle', 'helipad','noise']\n",
    "#CLASS={'tennis-court', 'container-crane', 'storage-tank', 'baseball-diamond', 'plane', 'ground-track-field', 'helicopter', 'airport', 'harbor', 'ship', 'large-vehicle', 'swimming-pool', 'soccer-ball-field', 'roundabout', 'basketball-court', 'bridge', 'small-vehicle', 'helipad'}\n",
    "class_to_ind = dict(zip(CLASS, range(len(CLASS))))\n",
    "print(class_to_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bbox_overlaps_py(boxes, query_boxes):\n",
    "    \"\"\"\n",
    "    determine overlaps between boxes and query_boxes\n",
    "    :param boxes: n * 4 bounding boxes\n",
    "    :param query_boxes: k * 4 bounding boxes\n",
    "    :return: overlaps: n * k overlaps\n",
    "    \"\"\"\n",
    "    n_ = boxes.shape[0]\n",
    "    k_ = query_boxes.shape[0]\n",
    "    overlaps = np.zeros((n_, k_), dtype=np.float)\n",
    "    for k in range(k_):\n",
    "        query_box_area = (query_boxes[k, 2] - query_boxes[k, 0] + 1) * (query_boxes[k, 3] - query_boxes[k, 1] + 1)\n",
    "        for n in range(n_):\n",
    "            iw = min(boxes[n, 2], query_boxes[k, 2]) - max(boxes[n, 0], query_boxes[k, 0]) + 1\n",
    "            if iw > 0:\n",
    "                ih = min(boxes[n, 3], query_boxes[k, 3]) - max(boxes[n, 1], query_boxes[k, 1]) + 1\n",
    "                if ih > 0:\n",
    "                    box_area = (boxes[n, 2] - boxes[n, 0] + 1) * (boxes[n, 3] - boxes[n, 1] + 1)\n",
    "                    all_area = float(query_box_area)\n",
    "                    overlaps[n, k] = iw * ih / all_area\n",
    "    return overlaps\n",
    "\n",
    "def _pygenerate(boxes, masks, labels, width, height, chipsize, stride):\n",
    "        chips = []\n",
    "        boxes = np.array(boxes)\n",
    "        masks = np.array(masks)\n",
    "        # ensure coverage of image for worst case\n",
    "        # corners\n",
    "        chips.append([max(width - chipsize, 0), 0, width - 1, min(chipsize, height-1)])\n",
    "        chips.append([0, max(height - chipsize, 0), min(chipsize, width-1), height-1])\n",
    "        chips.append([max(width - chipsize, 0), max(height - chipsize, 0), width-1, height-1])\n",
    "\t\t\n",
    "        for i in range(0, width - int(chipsize), stride):\n",
    "            for j in range(0, height - int(chipsize), stride):\n",
    "                x1 = i\n",
    "                y1 = j\n",
    "                x2 = i + chipsize - 1\n",
    "                y2 = j + chipsize - 1\n",
    "                chips.append([x1, y1, x2, y2])\n",
    "\t\t#width may not be divide by stride\n",
    "        for j in range(0, height - int(chipsize), stride):\n",
    "            x1 = max(width - chipsize - 1,0)\n",
    "            y1 = j\n",
    "            x2 = width - 1\n",
    "            y2 = j + chipsize - 1\n",
    "            chips.append([x1, y1, x2, y2])\n",
    "\t\t#the same as above\n",
    "        for i in range(0, width - int(chipsize), stride):\n",
    "            x1 = i\n",
    "            y1 = max(height - chipsize - 1,0)\n",
    "            x2 = i + chipsize - 1\n",
    "            y2 = height - 1\n",
    "            chips.append([x1, y1, x2, y2])\n",
    "\n",
    "        chips = np.array(chips).astype(np.float)\n",
    "        overlaps = bbox_overlaps_py(chips, boxes.astype(np.float))\n",
    "        fchips = []\n",
    "        masks_list = []\n",
    "        boxes_list = []\n",
    "        labels_list = []\n",
    "        for j in range(len(chips)):\n",
    "            nvids = np.where(overlaps[j, :] >= 0.9)[0]\n",
    "            if(len(nvids) == 0):\n",
    "                continue\n",
    "            else:\n",
    "                fchips.append(chips[j])\n",
    "                boxes_list.append(boxes[nvids])\n",
    "                masks_list.append(masks[nvids])\n",
    "                labels_list.append([labels[x] for x in nvids])\n",
    "        return fchips, masks_list, boxes_list, labels_list\n",
    "def get_scale_info(fp, scale):\n",
    "    masks = []\n",
    "    labels = []\n",
    "    boxes = []\n",
    "    for line in fp:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        items = line.split(' ')\n",
    "        loc = np.array([float(x) for x in items[:8]])\n",
    "        loc = loc*scale\n",
    "        xs = loc[0::2]\n",
    "        ys = loc[1::2]\n",
    "        poly = np.array([[[loc[0],loc[1]],[loc[2],loc[3]],[loc[4],loc[5]],[loc[6], loc[7]]]], np.int32)\n",
    "        area = cv2.contourArea(poly)\n",
    "        if(area < 50):\n",
    "            continue\n",
    "        xmin  = min(xs)\n",
    "        xmax = max(xs)\n",
    "        ymin = min(ys)\n",
    "        ymax = max(ys)\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        cls = items[8]\n",
    "        if cls not in CLASS:\n",
    "            continue\n",
    "        labels.append(cls)\n",
    "        masks.append(loc)\n",
    "        boxes.append([xmin,ymin,xmax,ymax])\n",
    "    return labels, masks, boxes\n",
    "def construct_imginfo(filename, h, w, ID):\n",
    "    image = { \"license\": 1,\n",
    "              \"file_name\": filename,\n",
    "              \"coco_url\": \"xxx\",\n",
    "              \"height\": h,\n",
    "              \"width\": w,\n",
    "              \"date_captured\": \"2019-06-25\",\n",
    "              \"flickr_url\": \"xxx\",\n",
    "              \"id\": ID\n",
    "            }\n",
    "    return image\n",
    "\n",
    "def construct_ann(obj_id, ID, category_id, seg, area, bbox):\n",
    "    ann = {\"id\" : obj_id, \n",
    "                \"image_id\" : ID, \n",
    "                \"category_id\" : category_id, \n",
    "                \"segmentation\" : seg, \n",
    "               \"area\" :  area, \n",
    "               \"bbox\" : bbox, \n",
    "               \"iscrowd\" : 0,\n",
    "            }\n",
    "    return ann\n",
    "\n",
    "def generate_ann(box, mask, label, xmin, ymin):\n",
    "    ann = []\n",
    "    for b, loc, l in zip(box, mask, label):\n",
    "        x1, y1, x2, y2 = b\n",
    "        x1 -= xmin\n",
    "        y1 -= ymin\n",
    "        x2 -= xmin\n",
    "        y2 -= ymin\n",
    "        poly = np.array([[[loc[0],loc[1]],[loc[2],loc[3]],[loc[4],loc[5]],[loc[6], loc[7]]]], np.int32)\n",
    "        box = [x1, y1, x2, y2]\n",
    "        area = cv2.contourArea(poly)\n",
    "        poly = [loc[0]-xmin,loc[1]-ymin,loc[2]-xmin,loc[3]-ymin,loc[4]-xmin,loc[5]-ymin,loc[6]-xmin, loc[7]-ymin]\n",
    "        obj = [class_to_ind[l], [poly], area, [x1, y1, x2-x1, y2-y1]]\n",
    "        ann.append(obj)\n",
    "    return ann\n",
    "\n",
    "def chip_warpper(mode, chip, imgname, img, box, mask, label, scale, outdir, phase=\"train\", count=0):\n",
    "    if mode == \"multi\":\n",
    "        xmin, ymin, xmax, ymax = chip\n",
    "        filename = imgname.split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(xmin), str(ymin), str(0))+\"part\" +str(count) + \".jpg\"\n",
    "        cv2.imwrite(\"{}/{}\".format(outdir, phase)+filename, img)\n",
    "        h, w,_ = img.shape\n",
    "        ann = generate_ann(box, mask, label, xmin, ymin)\n",
    "    else:\n",
    "        filename = imgname.split(\".\")[0] + \"_{}_{}_{}_{}\".format(str(scale), str(0), str(0), str(0))+\"part\" +str(0) + \".jpg\"\n",
    "        h, w,_ = img.shape\n",
    "        cv2.imwrite(\"{}/{}\".format(outdir, phase)+filename, img)\n",
    "        ann = generate_ann(box, mask, label, 0, 0)\n",
    "    return (ann, filename, h, w)\n",
    "   \n",
    "\n",
    "def scale_generate(datdir, labeldir, phase, outdir, SCALE):\n",
    "    imgs = os.listdir(datadir)\n",
    "    info = {\n",
    "        \"description\": \"rscup\",\n",
    "        \"url\": \"http://cocodataset.org\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2014,\n",
    "        \"contributor\": \"COCO Consortium\",\n",
    "        \"date_created\": \"2017/09/01\"\n",
    "      }\n",
    "    license = [{ \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\", \"id\": 1, \"name\": \"Attribution-NonCommercial-ShareAlike License\"} ]\n",
    "    categories = []\n",
    "    for cls in CLASS:\n",
    "        category = { \"id\" : class_to_ind[cls], \"name\" : cls, \"supercategory\" : \"object\",}\n",
    "        categories.append(category)\n",
    "    print(categories)\n",
    "    annotations = {\"info\": info, \"images\": [], \"annotations\": [], \"categories\":categories, \"license\":license}\n",
    "    obj_id = 0\n",
    "    ID = 0\n",
    "    p = Pool(18)\n",
    "    for img_id in tqdm(range(len(imgs))):\n",
    "        img_path = os.path.join(datadir, imgs[img_id])\n",
    "        label_path = os.path.join(labeldir, imgs[img_id].split(\".\")[0]+\".txt\")\n",
    "        original_img = cv2.imread(img_path)\n",
    "        scales = copy.deepcopy(SCALE)\n",
    "        fp = open(label_path).readlines()[2:]\n",
    "        rets = []\n",
    "        for scale in scales:\n",
    "            img, scale_factor = mmcv.imrescale(original_img, scale, return_scale=True)\n",
    "            H,W,_ = img.shape\n",
    "            labels, masks, boxes = get_scale_info(fp, scale_factor)\n",
    "            if(len(labels)<=0):\n",
    "                continue\n",
    "            if max(H,W) > 512:\n",
    "                print(np.array(masks).shape)\n",
    "                print(len(labels))\n",
    "                fchips, masks, boxes, labels = chips.generate(boxes, masks, labels, W, H, 512, 416)\n",
    "                count = 0\n",
    "                for chip, mask, box, label in zip(fchips, masks, boxes,labels):\n",
    "                    count+=1\n",
    "                    xmin, ymin, xmax, ymax = chip\n",
    "                    img2 = copy.deepcopy(img[int(ymin):int(ymax), int(xmin):int(xmax),:])\n",
    "                    rets.append(p.apply_async(chip_warpper, args=(\"multi\", chip, imgs[img_id], img2, box, mask, label, scale, outdir, count)))\n",
    "            else:\n",
    "                rets.append(p.apply_async(chip_warpper, args=(\"single\", None, imgs[img_id], img, boxes, masks, labels, scale, outdir, count)))\n",
    "        for ret in rets:\n",
    "            anns, filename, h, w = ret.get()\n",
    "            image = construct_imginfo(filename, h, w, ID)\n",
    "            annotations[\"images\"].append(image)\n",
    "            for ann in anns:\n",
    "                category_id, seg, area, bbox = ann\n",
    "                ann_info = construct_ann(obj_id, ID, category_id, seg, area, bbox)\n",
    "                annotations[\"annotations\"].append(ann_info)\n",
    "                obj_id += 1\n",
    "            ID += 1\n",
    "    p.close()\n",
    "    p.join()\n",
    "    with open('{}/annos_rscup_'.format(outdir)+phase+'.json', 'w') as json_file:\n",
    "        json.dump(annotations, json_file, cls=MyEncoder)\n",
    "    print(\"totol number {}\".format(str(ID)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tennis-court': 0, 'container-crane': 1, 'storage-tank': 2, 'baseball-diamond': 3, 'plane': 4, 'ground-track-field': 5, 'helicopter': 6, 'airport': 7, 'harbor': 8, 'ship': 9, 'large-vehicle': 10, 'swimming-pool': 11, 'soccer-ball-field': 12, 'roundabout': 13, 'basketball-court': 14, 'bridge': 15, 'small-vehicle': 16, 'helipad': 17}\n",
      "[{'id': 0, 'name': 'tennis-court', 'supercategory': 'object'}, {'id': 1, 'name': 'container-crane', 'supercategory': 'object'}, {'id': 2, 'name': 'storage-tank', 'supercategory': 'object'}, {'id': 3, 'name': 'baseball-diamond', 'supercategory': 'object'}, {'id': 4, 'name': 'plane', 'supercategory': 'object'}, {'id': 5, 'name': 'ground-track-field', 'supercategory': 'object'}, {'id': 6, 'name': 'helicopter', 'supercategory': 'object'}, {'id': 7, 'name': 'airport', 'supercategory': 'object'}, {'id': 8, 'name': 'harbor', 'supercategory': 'object'}, {'id': 9, 'name': 'ship', 'supercategory': 'object'}, {'id': 10, 'name': 'large-vehicle', 'supercategory': 'object'}, {'id': 11, 'name': 'swimming-pool', 'supercategory': 'object'}, {'id': 12, 'name': 'soccer-ball-field', 'supercategory': 'object'}, {'id': 13, 'name': 'roundabout', 'supercategory': 'object'}, {'id': 14, 'name': 'basketball-court', 'supercategory': 'object'}, {'id': 15, 'name': 'bridge', 'supercategory': 'object'}, {'id': 16, 'name': 'small-vehicle', 'supercategory': 'object'}, {'id': 17, 'name': 'helipad', 'supercategory': 'object'}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa6b80648284cc4955bee96a387a72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1830), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(582, 8)\n",
      "582\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "generate() takes exactly 5 positional arguments (7 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-05bfc700ab6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdatadir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/xfr/rssid/data/train/images\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlabeldir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/xfr/rssid/data/train/labelTxt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscale_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeldir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./data/trash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-0ee24d24fbd0>\u001b[0m in \u001b[0;36mscale_generate\u001b[0;34m(datdir, labeldir, phase, outdir, SCALE)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mfchips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfchips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mchips.pyx\u001b[0m in \u001b[0;36mchips.generate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: generate() takes exactly 5 positional arguments (7 given)"
     ]
    }
   ],
   "source": [
    "CLASS=['tennis-court', 'container-crane', 'storage-tank', 'baseball-diamond', 'plane', 'ground-track-field', 'helicopter', 'airport', 'harbor', 'ship', 'large-vehicle', 'swimming-pool', 'soccer-ball-field', 'roundabout', 'basketball-court', 'bridge', 'small-vehicle', 'helipad']\n",
    "#CLASS={'tennis-court', 'container-crane', 'storage-tank', 'baseball-diamond', 'plane', 'ground-track-field', 'helicopter', 'airport', 'harbor', 'ship', 'large-vehicle', 'swimming-pool', 'soccer-ball-field', 'roundabout', 'basketball-court', 'bridge', 'small-vehicle', 'helipad'}\n",
    "class_to_ind = dict(zip(CLASS, range(len(CLASS))))\n",
    "print(class_to_ind)\n",
    "datadir = \"/home/xfr/rssid/data/train/images\"\n",
    "labeldir = \"/home/xfr/rssid/data/train/labelTxt\"\n",
    "scale_generate(datadir, labeldir, \"train\",\"./data/trash\", [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chips.chips as chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "mmdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
